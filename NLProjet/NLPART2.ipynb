{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eeca778",
   "metadata": {
    "id": "5eeca778"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf865172",
   "metadata": {
    "id": "bf865172"
   },
   "source": [
    "This notebook includes a comparison of the performance of the selected models. It presents a table and a bar chart to visualize and compare the training and testing scores of these models using both BOW and TF-IDF representations.\n",
    "We use these techniques and models to explore text classification, and the choice of representation and model depends on the specific goals and characteristics of the dataset. The comparison of the models provides insight into their relative performance for the task of classifying stress-related messages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0d56de",
   "metadata": {
    "id": "7e0d56de"
   },
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27ae6424",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27ae6424",
    "outputId": "8f7c9b71-cc0c-492f-8224-c2f4e419a639"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                    text  label\n",
      "0     He said he had not felt that way before, sugge...      1\n",
      "1     Hey there r/assistance, Not sure if this is th...      0\n",
      "2     My mom then hit me with the newspaper and it s...      1\n",
      "3     until i met my new boyfriend, he is amazing, h...      1\n",
      "4     October is Domestic Violence Awareness Month a...      1\n",
      "...                                                 ...    ...\n",
      "2833  * Her, a week ago: Precious, how are you? (I i...      0\n",
      "2834  I don't have the ability to cope with it anymo...      1\n",
      "2835  In case this is the first time you're reading ...      0\n",
      "2836  Do you find this normal? They have a good rela...      0\n",
      "2837  I was talking to my mom this morning and she s...      1\n",
      "\n",
      "[2838 rows x 2 columns]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet2022 to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nicol\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Data Loading and Exploration\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "df = pd.read_csv(\"Stress.csv\")\n",
    "\n",
    "not_used_cols = ['subreddit','post_id','sentence_range','confidence','social_timestamp']\n",
    "df1 = df.drop(not_used_cols,axis=1)\n",
    "df1['label'].unique()\n",
    "#Text processing\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "#from spacy import load\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('omw-1.4') # Open Multilingual Wordnet, this is an lexical database\n",
    "nltk.download('wordnet')\n",
    "nltk.download('wordnet2022')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "print(df1.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43610fd",
   "metadata": {
    "id": "c43610fd"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "def textProcess(sent):\n",
    "    try:\n",
    "        # Replace square brackets, parentheses with spaces\n",
    "        sent = re.sub('[][)(]', ' ', sent)\n",
    "\n",
    "        # Remove URLs by checking if a word has a URL scheme\n",
    "        sent = [word for word in sent.split() if not urlparse(word).scheme]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # Remove escape characters starting with '@'\n",
    "        sent = re.sub(r'\\@\\w+', '', sent)\n",
    "\n",
    "        # Remove HTML tags using regular expressions\n",
    "        sent = re.sub(re.compile(\"<.*?>\"), '', sent)\n",
    "\n",
    "        # Keep only letters and numbers, replace others with spaces\n",
    "        sent = re.sub(\"[^A-Za-z0-9]\", ' ', sent)\n",
    "\n",
    "        # Convert all words to lowercase\n",
    "        sent = sent.lower()\n",
    "\n",
    "        # Strip extra spaces from words and sentences\n",
    "        sent = [word.strip() for word in sent.split()]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(sent)\n",
    "\n",
    "        # Remove stopwords (common words that don't carry much meaning)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Lemmatize the words (convert words to their base form)\n",
    "        sent = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        return sent\n",
    "\n",
    "    except Exception as ex:\n",
    "        # Handle exceptions and print an error message\n",
    "        print(sent, \"\\n\")\n",
    "        print(\"Error \", ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f7ec7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3f7ec7e",
    "outputId": "15519ab7-07ec-4d97-880a-1fce2e1d1468"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.info of 0       said felt way suggeted go rest trigger ahead y...\n",
       "1       hey r assistance sure right place post go curr...\n",
       "2       mom hit newspaper shocked would know like play...\n",
       "3       met new boyfriend amazing kind sweet good stud...\n",
       "4       october domestic violence awareness month dome...\n",
       "                              ...                        \n",
       "2833    week precious ignored jan happy year precious ...\n",
       "2834    ability cope anymore trying lot thing triggeri...\n",
       "2835    case first time reading post looking people wi...\n",
       "2836    find normal good relationship main problem see...\n",
       "2837    talking mom morning said sister trauma worse m...\n",
       "Name: processed_text, Length: 2838, dtype: object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['processed_text'] = df1['text'].apply(lambda text: textProcess(text))\n",
    "df1['processed_text'].info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a744bfe0",
   "metadata": {
    "id": "a744bfe0"
   },
   "source": [
    "## BOW (Bag Of Word) / TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453968a3",
   "metadata": {
    "id": "453968a3"
   },
   "source": [
    "\n",
    "### Bag of Words (BOW):\n",
    "\n",
    "BOW is a straightforward and effective method for text classification with a quickly understand of the word frequency distribution in documents, which is essential for our classification task. BOW identifying important keywords in documents, aiding our content comprehension by highlighting key terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdda422",
   "metadata": {
    "id": "5bdda422"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = list(stopwords.words('english'))\n",
    "def textProcess(sent):\n",
    "    try:\n",
    "        # Replace square brackets, parentheses with spaces\n",
    "        sent = re.sub('[][)(]', ' ', sent)\n",
    "\n",
    "        # Remove URLs by checking if a word has a URL scheme\n",
    "        sent = [word for word in sent.split() if not urlparse(word).scheme]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # Remove escape characters starting with '@'\n",
    "        sent = re.sub(r'\\@\\w+', '', sent)\n",
    "\n",
    "        # Remove HTML tags using regular expressions\n",
    "        sent = re.sub(re.compile(\"<.*?>\"), '', sent)\n",
    "\n",
    "        # Keep only letters and numbers, replace others with spaces\n",
    "        sent = re.sub(\"[^A-Za-z0-9]\", ' ', sent)\n",
    "\n",
    "        # Convert all words to lowercase\n",
    "        sent = sent.lower()\n",
    "\n",
    "        # Strip extra spaces from words and sentences\n",
    "        sent = [word.strip() for word in sent.split()]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        # Tokenize the text into words\n",
    "        tokens = word_tokenize(sent)\n",
    "\n",
    "        # Remove stopwords (common words that don't carry much meaning)\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Lemmatize the words (convert words to their base form)\n",
    "        sent = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        sent = ' '.join(sent)\n",
    "\n",
    "        return sent\n",
    "\n",
    "    except Exception as ex:\n",
    "        # Handle exceptions and print an error message\n",
    "        print(sent, \"\\n\")\n",
    "        print(\"Error \", ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd076d9",
   "metadata": {
    "id": "9dd076d9"
   },
   "outputs": [],
   "source": [
    "df1['processed_text'] = df1['text'].apply(lambda text: textProcess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7a4de",
   "metadata": {
    "id": "01f7a4de"
   },
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68d0e80",
   "metadata": {
    "id": "e68d0e80"
   },
   "source": [
    "Bag of Words (BOW):\n",
    "\n",
    "BOW is a straightforward and effective method for text classification with a quickly understand of the word frequency distribution in documents, which is essential for our classification task. BOW identifying important keywords in documents, aiding our content comprehension by highlighting key terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e37139f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "9e37139f",
    "outputId": "7325e372-af0c-4540-e6b8-6f3e4571d6b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100kg</th>\n",
       "      <th>100mg</th>\n",
       "      <th>100x</th>\n",
       "      <th>...</th>\n",
       "      <th>zines</th>\n",
       "      <th>zinsser</th>\n",
       "      <th>zip</th>\n",
       "      <th>zofran</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  02  06  10  100  1000  100kg  100mg  100x  ...  zines  zinsser  \\\n",
       "0   0    0   0   0   0    0     0      0      0     0  ...      0        0   \n",
       "1   0    0   0   0   0    0     0      0      0     0  ...      0        0   \n",
       "2   0    0   0   0   0    0     0      0      0     0  ...      0        0   \n",
       "\n",
       "   zip  zofran  zoloft  zombie  zone  zoo  zuko  zumba  \n",
       "0    0       0       0       0     0    0     0      0  \n",
       "1    0       0       0       0     0    0     0      0  \n",
       "2    0       0       0       0     0    0     0      0  \n",
       "\n",
       "[3 rows x 10140 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "MIN_DF = 1\n",
    "# min_df is used for removing terms that appear too infrequently.\n",
    "# For example: min_df = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    "cv = CountVectorizer(min_df=MIN_DF)\n",
    "cv_df = cv.fit_transform(df1['processed_text'])\n",
    "cv_df.toarray()\n",
    "\n",
    "cv_df = pd.DataFrame(cv_df.toarray(),columns=cv.get_feature_names_out())\n",
    "cv_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2cf371",
   "metadata": {
    "id": "7f2cf371"
   },
   "source": [
    "### Term Frequency-Inverse Document Frequency (TF-IDF):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57e939",
   "metadata": {
    "id": "cd57e939"
   },
   "source": [
    "\n",
    "TF-IDF addresses this by giving higher scores to words that are frequent in a specific document but rare across the entire corpus.\n",
    "That helps emphasize discriminative terms for classification and reduces the impact of common words like \"the\" and \"and.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9883d",
   "metadata": {
    "id": "f8c9883d"
   },
   "source": [
    "TF-IDF (Term frequency - inverse document frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02d786ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02d786ab",
    "outputId": "67b4e2a4-89dd-43bf-c4fe-a5aa43b7d044"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(min_df=MIN_DF)\n",
    "tf_df = tf.fit_transform(df1['processed_text'])\n",
    "tf_df.toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01987a2",
   "metadata": {
    "id": "a01987a2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0213620",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "a0213620",
    "outputId": "d2a727fa-f2a3-4a32-9485-1ce897a1ad00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100kg</th>\n",
       "      <th>100mg</th>\n",
       "      <th>100x</th>\n",
       "      <th>...</th>\n",
       "      <th>zines</th>\n",
       "      <th>zinsser</th>\n",
       "      <th>zip</th>\n",
       "      <th>zofran</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 10140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000   02   06   10  100  1000  100kg  100mg  100x  ...  zines  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0    0.0   0.0  ...    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0    0.0   0.0  ...    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0    0.0   0.0  ...    0.0   \n",
       "\n",
       "   zinsser  zip  zofran  zoloft  zombie  zone  zoo  zuko  zumba  \n",
       "0      0.0  0.0     0.0     0.0     0.0   0.0  0.0   0.0    0.0  \n",
       "1      0.0  0.0     0.0     0.0     0.0   0.0  0.0   0.0    0.0  \n",
       "2      0.0  0.0     0.0     0.0     0.0   0.0  0.0   0.0    0.0  \n",
       "\n",
       "[3 rows x 10140 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame(tf_df.toarray(),columns=tf.get_feature_names_out())\n",
    "tf_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "504a431a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "id": "504a431a",
    "outputId": "e85b80c3-4218-431b-f536-eb5ac40c0fc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>02</th>\n",
       "      <th>06</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100kg</th>\n",
       "      <th>100mg</th>\n",
       "      <th>100x</th>\n",
       "      <th>...</th>\n",
       "      <th>zines</th>\n",
       "      <th>zinsser</th>\n",
       "      <th>zip</th>\n",
       "      <th>zofran</th>\n",
       "      <th>zoloft</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zumba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "      <td>2838.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>0.022159</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004252</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.265556</td>\n",
       "      <td>0.337824</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.209957</td>\n",
       "      <td>0.277953</td>\n",
       "      <td>0.298782</td>\n",
       "      <td>0.324070</td>\n",
       "      <td>0.299611</td>\n",
       "      <td>0.231738</td>\n",
       "      <td>0.200569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226519</td>\n",
       "      <td>0.208890</td>\n",
       "      <td>0.357795</td>\n",
       "      <td>0.228713</td>\n",
       "      <td>0.314832</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>0.286642</td>\n",
       "      <td>0.266303</td>\n",
       "      <td>0.165859</td>\n",
       "      <td>0.113743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 10140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                00          000           02           06           10  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.000176     0.000570     0.000112     0.000074     0.003420   \n",
       "std       0.006641     0.010400     0.005943     0.003941     0.022159   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.265556     0.337824     0.316593     0.209957     0.277953   \n",
       "\n",
       "               100         1000        100kg        100mg         100x  ...  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  ...   \n",
       "mean      0.001897     0.000607     0.000106     0.000122     0.000071  ...   \n",
       "std       0.018407     0.011747     0.005624     0.004854     0.003765  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "max       0.298782     0.324070     0.299611     0.231738     0.200569  ...   \n",
       "\n",
       "             zines      zinsser          zip       zofran       zoloft  \\\n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000   \n",
       "mean      0.000080     0.000074     0.000212     0.000081     0.000748   \n",
       "std       0.004252     0.003921     0.008125     0.004293     0.012308   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       0.226519     0.208890     0.357795     0.228713     0.314832   \n",
       "\n",
       "            zombie         zone          zoo         zuko        zumba  \n",
       "count  2838.000000  2838.000000  2838.000000  2838.000000  2838.000000  \n",
       "mean      0.000136     0.000257     0.000094     0.000058     0.000040  \n",
       "std       0.005144     0.007226     0.004999     0.003113     0.002135  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       0.201190     0.286642     0.266303     0.165859     0.113743  \n",
       "\n",
       "[8 rows x 10140 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b143e1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b143e1a",
    "outputId": "107f7055-5c4e-47ca-d516-8189ee3a164e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2838, 10140), (2838, 10140))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df.shape,tf_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d7261c",
   "metadata": {
    "id": "30d7261c"
   },
   "source": [
    "### Choose the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f87612",
   "metadata": {
    "id": "e3f87612"
   },
   "source": [
    "Each case explores a different combination of model and feature representation.\n",
    "\n",
    "The choice between models and representations may depend on the specific characteristics of our data and the trade-off between simplicity and complexity in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33f4040",
   "metadata": {
    "id": "a33f4040"
   },
   "source": [
    "BOW treats all words equally, including common ones that may not be informative for classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7e8bac",
   "metadata": {
    "id": "ba7e8bac"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cv_df, df1['label'], stratify=df1['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b43f4e",
   "metadata": {
    "id": "a6b43f4e"
   },
   "source": [
    " Logistic Regression is chosen for its simplicity and interpretability. Bag of Words (BOW) representation is used, which creates a vocabulary of words and encodes each document as a vector of word counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7b6105",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "3a7b6105",
    "outputId": "592960dd-fb63-458b-c247-7e9e29871479"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the models and train them\n",
    "# Logistic Regression with BOW\n",
    "model_lr_bow = LogisticRegression()\n",
    "model_lr_bow.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d64ef1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d64ef1c",
    "outputId": "e3868e86-d066-4f40-8210-ff2225fe9121"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9967105263157895\n",
      "0.7281690140845071\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the models on the test set\n",
    "# Logistic Regression with BOW\n",
    "lr_bow_train_score = model_lr_bow.score(X_train, y_train)\n",
    "lr_bow_test_score = model_lr_bow.score(X_test, y_test)\n",
    "\n",
    "print(lr_bow_train_score)\n",
    "print(lr_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f804e49f",
   "metadata": {
    "id": "f804e49f"
   },
   "source": [
    "Naive Bayes is selected for its effectiveness in handling text data. It's also based on the BOW representation, Naive Bayes makes strong independence assumptions between features, which can work well with BOW. It's computationally efficient and often used in text classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08cdf996",
   "metadata": {
    "id": "08cdf996"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes with BOW\n",
    "model_nb_bow = MultinomialNB()\n",
    "model_nb_bow.fit(X_train, y_train)\n",
    "# Scores\n",
    "nb_bow_train_score = model_nb_bow.score(X_train, y_train)\n",
    "nb_bow_test_score = model_nb_bow.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f9becd",
   "metadata": {
    "id": "59f9becd"
   },
   "source": [
    "Random Forest is a more complex model capable of capturing non-linear relationships in the data with BOW features that can capture intricate patterns in text data and provide better generalization by aggregating multiple decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e46ce95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "5e46ce95",
    "outputId": "feff6e9d-632c-47b3-cb52-09bec968531f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest with BOW\n",
    "model_rf_bow = RandomForestClassifier()\n",
    "model_rf_bow.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f54bef",
   "metadata": {
    "id": "78f54bef"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest with BOW\n",
    "rf_bow_train_score = model_rf_bow.score(X_train, y_train)\n",
    "rf_bow_test_score = model_rf_bow.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc848b2c",
   "metadata": {
    "id": "dc848b2c"
   },
   "source": [
    "TF-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdaeac8",
   "metadata": {
    "id": "2fdaeac8"
   },
   "source": [
    "Term Frequency-Inverse Document Frequency (TF-IDF):\n",
    "\n",
    "BOW treats all words equally, including common ones that may not be informative for classification.\n",
    "TF-IDF addresses this by giving higher scores to words that are frequent in a specific document but rare across the entire corpus.\n",
    "That helps emphasize discriminative terms for classification and reduces the impact of common words like \"the\" and \"and.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d364d4",
   "metadata": {
    "id": "e1d364d4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Repeat the same steps for TF-IDF\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tf_df, df1['label'], stratify=df1['label'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98242bf",
   "metadata": {
    "id": "b98242bf"
   },
   "source": [
    "Logistic Regression with the Term Frequency-Inverse Document Frequency (TF-IDF) representation.\n",
    "TF-IDF assigns weights to words based on their importance that can highlight the significance of words in documents, and Logistic Regression can efficiently handle these weighted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b17192d",
   "metadata": {
    "id": "0b17192d"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with TF-IDF\n",
    "model_lr_tfidf = LogisticRegression()\n",
    "model_lr_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "# Evaluate the models on the test set\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf_train_score = model_lr_tfidf.score(X_train_tfidf, y_train_tfidf)\n",
    "lr_tfidf_test_score = model_lr_tfidf.score(X_test_tfidf, y_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05636a2",
   "metadata": {
    "id": "b05636a2"
   },
   "source": [
    "Naive Bayes with TF-IDF is a robust choice when considering term importance.\n",
    "Very useful when certain words are more informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba0b5349",
   "metadata": {
    "id": "ba0b5349"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes with TF-IDF\n",
    "model_nb_tfidf = MultinomialNB()\n",
    "model_nb_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "\n",
    "# Naive Bayes with TF-IDF\n",
    "nb_tfidf_train_score = model_nb_tfidf.score(X_train_tfidf, y_train_tfidf)\n",
    "nb_tfidf_test_score = model_nb_tfidf.score(X_test_tfidf, y_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a626368",
   "metadata": {
    "id": "5a626368"
   },
   "source": [
    "Random Forest is used with TF-IDF features for its ability to handle high-dimensional data and can effectively exploit the weighted word features provided by TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee2d1992",
   "metadata": {
    "id": "ee2d1992"
   },
   "outputs": [],
   "source": [
    "# Random Forest with TF-IDF\n",
    "model_rf_tfidf = RandomForestClassifier()\n",
    "model_rf_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "# Random Forest with TF-IDF\n",
    "rf_tfidf_train_score = model_rf_tfidf.score(X_train_tfidf, y_train_tfidf)\n",
    "rf_tfidf_test_score = model_rf_tfidf.score(X_test_tfidf, y_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a33c1bf",
   "metadata": {
    "id": "0a33c1bf"
   },
   "source": [
    "Comparaison between all model choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c8251e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8c8251e0",
    "outputId": "7b510afb-cf3f-43de-8c00-2741ac9b6b19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             Model  Train Score (BOW)  Test Score (BOW)  \\\n",
      "0     Logistic Regression with BOW           0.996711          0.728169   \n",
      "1             Naive Bayes with BOW           0.926222          0.747887   \n",
      "2           Random Forest with BOW           0.998120          0.728169   \n",
      "3  Logistic Regression with TF-IDF           0.000000          0.000000   \n",
      "4          Naive Bayes with TF-IDF           0.000000          0.000000   \n",
      "5        Random Forest with TF-IDF           0.000000          0.000000   \n",
      "\n",
      "   Train Score (TF-IDF)  Test Score (TF-IDF)  \n",
      "0              0.000000             0.000000  \n",
      "1              0.000000             0.000000  \n",
      "2              0.000000             0.000000  \n",
      "3              0.914474             0.729577  \n",
      "4              0.863252             0.695775  \n",
      "5              0.999060             0.688732  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the model names and their respective scores\n",
    "scores_data = {\n",
    "    'Model': ['Logistic Regression with BOW', 'Naive Bayes with BOW', 'Random Forest with BOW',\n",
    "              'Logistic Regression with TF-IDF', 'Naive Bayes with TF-IDF', 'Random Forest with TF-IDF'],\n",
    "    'Train Score (BOW)': [lr_bow_train_score, nb_bow_train_score, rf_bow_train_score, 0, 0, 0],\n",
    "    'Test Score (BOW)': [lr_bow_test_score, nb_bow_test_score, rf_bow_test_score, 0, 0, 0],\n",
    "    'Train Score (TF-IDF)': [0, 0, 0, lr_tfidf_train_score, nb_tfidf_train_score, rf_tfidf_train_score],\n",
    "    'Test Score (TF-IDF)': [0, 0, 0, lr_tfidf_test_score, nb_tfidf_test_score, rf_tfidf_test_score]\n",
    "}\n",
    "\n",
    "# Create a Pandas DataFrame\n",
    "scores_df = pd.DataFrame(scores_data)\n",
    "\n",
    "# Display the comparison table\n",
    "print(scores_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kHeysLvrMZrY",
   "metadata": {
    "id": "kHeysLvrMZrY"
   },
   "source": [
    "Now we need to Visualize to choose best model to conitnue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "YLLKO_ZyMYFe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "YLLKO_ZyMYFe",
    "outputId": "29ca60e7-1712-4389-9cf1-3cfa49c28b37"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAAsTAAALEwEAmpwYAABGD0lEQVR4nO3deXwV1f3/8fcnCTuKIBEQRJAtRDZLBLFQo4JAa7Wttq5VqJZq1YKKX7efXxartbVYd9RaXGpb/YpacauiAi6oBQWRJUjEDQRZDQTCEvL5/TETGa5ZyeQmgdfz8ZjHnXvOmZlP7pJ7P/ecOWPuLgAAAABA1aXUdAAAAAAAsK8gwQIAAACAmJBgAQAAAEBMSLAAAAAAICYkWAAAAAAQExIsAAAAAIgJCRaA2JjZTDPzcBlRhf2MiOxnZnwRJoeZdTCzf5rZCjPbVVf/Duzfwtdx8fuQa7oAQAWRYAF1VEISUrwcVUK7H5XQLjv5EVcvM/ushL/TzWyzmc0zs3FmdkAS4kiR9IyksyS1Ff9naxUz62pmt4WviW/MbLuZfW5mM8zsd2bWsqZjBADUbWk1HQCAWF0m6VcJZb+riUBqkaaS+oTL2Wb2fXdfV43H6xgeS5IKJf1S0gpJedV4TFSAmV0vaYKk1ISq9uGSrSAhvj2pgdVeqyQNqukgAKCuIcEC9i1nmdlV7r5ekswsQ9KQGo6pJjwkaYqkhpKGS7oiLO8q6XpJl8d9QDNr6u75Cnqtin3l7o/HfawSjolymNl1kn4fKXpf0n2Slks6QNIxks6rgdBqnbAXtoG7F0h6q6bjAYC6hqErwL6hQEFvSUNJv46UXybJJG0qa2Mza2Vmt5rZYjPbamYFZpZjZn8xs0NLaN/RzKaaWZ6ZbTKz58JkrqxjtDCzG83sQzPLD4+xyMzGm1nTyv/JZfrC3d9y91fd/UpJb0Tqjk+Iq7uZPWhmy81sW/j3vB0OwbSEtg9Hhh6ON7Nzw6Fm2yQ9ZmafSZoV2aR9tH1kP73N7NFwaNr28Jj/NbOxZtagMscM20TPfRtpZleGf09BuN8Tw3bDzOy9sHylmd1sZqkJxxtvZq+Z2Rfh87TDzL4ys2dKGlqaMBwz08xuivxdOWZ2bklPkJmdambPm9nq8Bjrwsf9/IR2VX7dmFkHSeMiRc9LGuDuD7r76+7+rLtfK6lTWBfdtirP1fnhe2qbmS00szPCdkeb2etmtsXM1prZfWbWOGFf0SGvJ5rZ/5jZsjCGT8zsagsSoeg2VXnuepnZHWa2UtJOSUOtjHOwzGy4mb0Sxr/TguGWORacezg8oW19MxttZu9Y8D9jh5l9Gbbtm/hcJcTVwszuMbNV4d/+gZkNLf3ZBoBawN1ZWFjq4CJphCQPl9WSngjXP1cwBKqZpM1h2e2Rti4pO7Kf7pK+TqiPLmsl9Yq0P1TB0KHEdhskfRq5PyKyTWdJX5ZxjI8ktSjlb5tZwcfjs8g24xPqno3ULY6U/0RBclpaXI9Jskj7hyN1Hye0/XdCDInL+HAfZ0raUUa7uZIOqOgxwzYzI2VLS9jnDkn/T1JRCXXXJDxWq8uIrUjSzxLaR+sT4yteBkTam4IextKO8e+9fd2U8dq4JuFvOLyCr6mqPFclPQ8u6QZJ20oov6+M1/OiUvZ1fzU+dz+R1CFaFtnuhFJeS9/5WyQ1kfROGW13Sjov0r6Dyo7LJW2v6HPIwsLCUhMLPVjAvuPu8La9pFMUnIvVVMEXknvK2O4xSYeE68sUTM7wc0mLw7KWkv4R+bX8Jkmtw/U8Sb8Nj/ehgi9HpR2jXbg+Q9JPJf1Yu3t7eqgaznsxswZmdqqkYZHieWFduqS/K+j1k4LhYsMUnDP1eVh2jqSRpey+i6S3JZ0h6UeSHpd0uvY85221gnNYBkmaYmatJf1NUr2w/iUFj8Nvtfscrb6SbqnEMRN1VnCe0Y8kLQnL6km6UdLr4fH+Gmk/OmH72yWdH26fLWmopOvCOgv3U5q2CoZjnippYaQ8+pj8WkECXWyqgsftFAVD+NZG6uJ63UR7SZa6++eltgzF8Fx1VfC++6H27EGdqOB5+Yn2HLJ4QRk9cp0VPAc/lPRIpHyUmX0/cv927f1z10nSJAVDan8p6ZMy2v4s3J8k3StpsILn71IFE7xEe8xvVDD8UpLyFbzeTlbwg4QUnKrwgJkdVsqxmit4zfxc0sqwrL6ki8qIDwBqVk1neCwsLHu3KKEHKyybH96fKSk3XH8prIv+ApwdlvVKKP9eZP9HJtQdrWBY8TeRst9F2reQtDVSNyIs7xEp2yHpJEkDw+W0hLqmJfxtMyv4eHym7/7SnbjkS+oRtr80Uv5RJKaBCr74Fte9EznGw5HyFZIalhBHdqTNZwl1v4vUrYluL+mSSF2epNRKHHNmpM0TkfKrIuUFCnt7FCTN0ccl2guTqeBL/HKV3NOS2D5aflWk/IxI+fuR8jmR8qfLeD4r/bopY1/TI+3fquDrqarP1XuR9j9PeJy6h+UpCpKR4vKepbye/5QQ24JI3R0xPXeTSngMOkTbRMpvipRfIalNKY+hSVoXbRupq68gYdrjtZN4TEk/j2xzdaT8qWT/z2VhYWGp6MIkF8C+5S5JD0o6LqGsNNHzpgrc/YPiO+6+yMy+kXRQpO0XCoYeFnsn0n6DmeVISpwqPjOyXk/Sy6XEUk9SNwWTD8TNFSQhV7p7cc9KNK4ekt4sZdsepZS/6O7bKhlH9PGem7B9dDKBAxUMxfxyL445O7K+PrK+1N03SJK7r7M9Ty9rIWmzmfVU8Jw2KecYzRUMP030WinHbhFZjz7uT5dxjDhfN99E1g8uo11UVZ+r0p6HPHdfIknuXmRmGxRMsiHt+ThFJU408baknuF6F0mK4bl7qpztov6uoCeqiYJer0lmlq+g1/JlSXeGr7V07fl4f/t3uPsOM/uvgp48ac/HO6oirykAqFUYIgjsW/6p4FyoYrkKhjbVFXFNdvGQgmF5AxUkfAe5+wnuPi/GmFbtbXBVUJFjRqeDL4qsf1PGNsXZ1mXa/QV9mYIhkj9Q0CsXVdpnR/S1V1jC/qtLea+baPLVtYzhaHGqyvOwN6r63FX49ezuOQouRfAHBcM1Vyl4Do5RMJnIy5YwecreKv5RIJTM1xQA7DUSLGAf4sG0yg9Giu5xdy9jk5zIeiOLXKjYzDK1u/equO1a7Xl+xTGR9i1U8q/QSyLrBQqSHUtcFAzzmlXC9nujeBbBt919vruXNItiNK7ZJcVUHFcpxyjrcS1N9PHua2YNI/ej59JsUslfePfmmJXRPrJ+p7v/093flLQrxmMsjqz/NLHSdnetxfm6+ZeCoYRS8Ll3l5l9ZwSHmTU0s87h3ao+V3H6fsL9YyPrueFtVZ+7Cr+2zMzcPdfdr3P3bHc/VFIbBcMaJSlLQc/aWu3Z6/T9yD7qKRh2XCz6eANAncYQQWDfc6eCL6RS0JNTKndfYGYfSPpeWPQvMxun4EvZuEjThQrOoykys2cUnEgvSRPNbIeCcymukNSohGN8ZGZzFHyZaiTpdTO7U8GQqnQFF+Y9QcEX38GV/WOr4AlJNytIoI41s6kKegDzFEzW0E3BpAL/VjBpRBz+T8Gv/o0VTCwy1czuUzCRw02Rdo+5e2EJ21e35ZH1Cy2Ydr6F9pyMoaoeVPAFXJJ+ZmaPK3gudiqYNKKdpF/H+bpx98/NbIJ2P8anSpptZvcr+JubSuqn4Ny/SQomi6hNz9XocCjhAgXnc/WK1P1feJuM567YleFU7C8omBBmg4KEKj3SpqG7u5k9qt3XnZtgZjvDWC/Q7mvGbVfJE7YAQJ1EggXsY9x9paTxldjklwpmaDtEQVKR+EVnvaRz3L14mNP1Cmbba6Wgh+u+sHyLgkSrrb7rHAUz2LVTkMw9XEKbuHqvKsTd15jZeQqSqoYKJk44rYSmz8Z4zNVmdoGkRxWcO/SjcIl6X9K1cR2zkiZLulBBbL0lPReWz5QU17C6vyroyfhleP+McCkWfbxje924+83hTJjjFVzG4Gjt2YOS2L42PVeLVfJshX9z9+LzmpLx3BVLU5DcnlBK/TwFyaAUTEs/QEFv9wH67jmhhZJGuXviOWwAUGcxRBDYz7n7YgW/iE9SMExnW7h8LOkOBdfAWhBpv1LBEKVnFJwsn69glrYfaPdwpcRjLAuPMVHBl698Bb9af6FgCuvrVQPTLrv7MwrO0XpAQezbFCSKuQouOHuRgmmo4zzm4wp6Sx5T0BuzU8Hj8b6k/5E0sJQhjdXO3T+SNETBZAlbFEwzf7eC6cnjOkaRu5+nYGr2FxXM0FeooBdktnZP3x3768bdf69g8ozbFVxWYJOCoYNfKkhExii8eHPYvrY8V2MV9BAvC+P9VMH067+JxFrtz13Ef8J9f6Ddz1+BgkTwVkknFv8g4+5bFEy6c7mk9xT8zyiU9JWCH3MGuPuj1RAjANQYK/v0DAAAkGzhEL/Dw7vHu/vMmosGAFAZ9GABAAAAQExIsAAAAAAgJiRYAAAAABATzsECAAAAgJjs89O0t2zZ0jt06FDTYQAAAADlev/999e5e3r5LVFb7fMJVocOHTR37tyaDgMAAAAol5l9XtMxoGo4BwsAAAAAYkKCBQAAAAAxIcECAAAAgJjs8+dgAQAAAHXZ+++/f0haWtqDknqIDpLaoEjSwsLCwgv79u27JrGSBAsAAACoxdLS0h5s3bp19/T09I0pKSlcY6mGFRUV2dq1azNXr179oKRTEuvJgAEAAIDarUd6evomkqvaISUlxdPT0/MU9Ch+tz7J8QAAAAConBSSq9olfD5KzKVIsAAAAAAgJpyDBQAAANQhf/jTn3vvKNgS2/f4+o2aFF77P2M/LKtNampq3y5duhS4u1JTU/2OO+74YsiQIVsk6eWXX246duzYw/Lz81Mk6ZJLLvl67Nix69atW5fauXPnnhs2bJifkpKiV199tcmQIUMycnNzF3Tq1Gnn+vXrU4844oieGzZsmJ+amlpunEOGDOn05ZdfNti6dWvKxo0b09q2bbtDku66667Pi2Mpy1FHHZUxb968nAo9KFVAggUAAADUITsKtqQ9VJAV2/5Gam65OUGDBg2KcnJyFkvSU089deB1113XbsiQIUu/+OKLtBEjRnR88sknPxk4cODWVatWpQ0ePLhLu3btdp555pl56enpO+fNm9ewb9++2958882m3bt33zpjxoymnTp12jhz5swmvXr12lKR5EqSpk+f/okkPf/88wdMmjSp1YwZM3Kj9Tt37lS9evVK3T4ZyZXEEEEAAAAAlZCXl5farFmzQkmaNGnSIWecccb6gQMHbpWkNm3aFN58880rbr311taSlJWVlT9r1qymkvTuu+82veSSS76ePXt2U0l66623mh5zzDH5VYnlzjvvPPiEE07ofMwxx3Q99thju+Xl5aUMGDCga2ZmZveuXbtmPvbYYwcVt23cuPFRUpCg9evXr9uwYcOO6Nix45GnnHJKx6KioqqEsQd6sAAAAACUafv27SkZGRmZ27dvt3Xr1tV78cUXP5akJUuWNDrvvPPWR9sOHDhwa25ubiNJOvbYY/PfeOONAySt++KLLxqMHDly45QpU9Il6b333mty9dVXr65qbIsWLWq8YMGCRa1atdq1c+dOvfDCC7ktWrQoWrVqVVr//v0zzj777G9SUvbsV1qyZEmj+fPnL+/QocPOvn37ZkyfPr3p0KFDq5TsFUtqD5aZHWZmM8xssZktMrPRJbQxM7vTzHLNbIGZfS9Sd76ZLQuX85MZOwAAALC/Kh4i+Omnny565plnlo0cObJCvT7Z2dn5c+fObZKTk1O/Xbt22xs3buzubnl5eSmLFi1qkp2dXe65U+UZNGjQplatWu2SgmtUjRkzpl3Xrl0zjz/++K5r1qypv2LFiu90KvXs2XNLp06ddqampurII4/c+sknn9SvahzFkj1EsFDSle6eKekYSZeYWWZCm+GSuoTLKEmTJcnMWkgaJ6m/pH6SxplZ82QFDgAAAEAaPHjwlo0bN6atWrUqLSMjo2Du3LmNo/Vvv/12486dOxdIUs+ePbdv3rw5berUqQf1798/X5J69eq15e67727Ztm3b7c2aNdsjSyssLFRGRkZmRkZG5pgxYw6tSDyNGzf+dh/3339/i/Xr16d99NFHS3JychYffPDBOwsKCr6T8zRo0ODbae9TU1NVWFholXsUSpfUBMvdV7n7B+H6ZklLJLVNaHaqpEc98K6kg8ysjaShkqa7+wZ33yhpuqRhSQwfAAAA2O/NmzevYVFRkVq1alV45ZVXrn3iiScOnj17diNJWr16dep1113X7sorr/x26F+fPn3y77///kMGDhy4RZIGDBiw5b777jvk6KOP/s6QvLS0NOXk5CzOyclZfPvtt39V2djy8vJSW7ZsubNBgwb+3HPPHfDVV1/F1jNVUTV2DpaZdZB0lKT3EqraSvoycn9FWFZaeUn7HqWg90vt27ePJ2AAAFDtbv/zH5W3ZVtNh1GnNWvSUGPGXl3TYaAa1W/UpLAiM/9VZn/ltSk+B0uS3F2TJ0/+LC0tTYcffvjOKVOmfDpq1KgOW7ZsSXF3u/jii78+++yz84q3HTBgQP6sWbOaFSdY2dnZ+RdddFGDY489tsrDAxNdeOGFG4YPH965a9eumb169drasWPHpP9DMffkXxTazJpKmiXpJnd/OqHueUm3uPtb4f3XJF0tKVtSQ3f/fVh+g6QCd/9zWcfKysryuXPnxv9HAACA2E2YMEHj/LaaDqNOm2BXaNy4cTUdBvaSmb3v7nvMwf7hhx9+1rt373U1FRNK9uGHH7bs3bt3h8TypE/Tbmb1JD0l6R+JyVVopaTDIvfbhWWllQMAAABArZDsWQRN0t8kLXEv9eepaZLOC2cTPEZSnruvkvSypJPMrHk4ucVJYRkAAAAA1ArJPgfr+5J+KekjM5sfll0nqb0kuft9kl6U9ENJuZK2ShoZ1m0wsxslzQm3m+juG5IXOgAAAACULakJVnheVZlTIHpwUtglpdRNkTSlGkIDAAAAgCpL+jlYAAAAALCvIsECAAAAgJjU2HWwAAAAAFTebX+6uffmgp2xfY8/oFG9wiv+57oPS6tfvXp1anZ2djdJWrduXb2UlBRv0aJFoSQtXbq0Ubdu3QqK2z777LO53bp12xHd/rTTTutw8skn540cOXJjv379uq1Zs6Ze/fr1i3bu3GmDBg3afNttt61s2bLlLklKTU3t26VLlzL3V5I77rjj4MmTJ7eSpE8++aRhx44dt6WkpOiEE07Iu/fee8udeXzMmDGHZmdnb/7JT36yuby25SHBAgAAAOqQzQU70+K8XtyEgivKzAlat269KycnZ7EkXXHFFYc2bdp018SJE7+WpMaNGx9VXFdRjz766PIf/OAHW7dt22aXXXZZ2+HDh3eeM2fOUklq0KBBUWX3J0mjR49eP3r06PWS1LZt256zZs36uE2bNntcQLmwsFBpaSX/qbfffvtXlT1maRgiCAAAACDpGjZs6JMnT17x1Vdf1X/nnXcaVccxGjdufNSvf/3rdt26dct87bXXmo4dO7ZNjx49unfp0uXIs8466/CioiJJQS/bQw891FwKErTLL7/80MzMzO5du3bNnDdvXsPKHJMECwAAAMBe2b59e0pGRkZmRkZG5pAhQzpVdvu0tDR1795968KFCxvGsb9EBQUFKf3799+ydOnSxUOHDs2/6qqr1ixcuHDJsmXLFhUUFKQ8/vjjzUrarmXLloWLFy9e8qtf/WrtLbfc0qpSf1NVgwYAAACwf9rbIX1RwVWa4ttfVGpqqkaMGLGx+P5LL710wG233dZ627ZtKd98801aZmZmgaS8xO3OPvvsjZLUr1+/rdOmTWtemWPSgwUAAAAgNqeffnqHjIyMzOOOO65zeW0LCwu1dOnSxr169dpWkX1fdtllbYt7uCrSvn79+kXF511t3brVrrzyysOffvrpTz7++OPF55577rpt27aVmA81bNjQJSktLc0LCwvLvI5vInqwAAAAAMRm6tSpn1Wk3fbt22306NFt27Rps6N///4F5W8h3XXXXSsllTsrYEm2bt2aIkmtW7cuzMvLS3nuueea//jHP95Y3naVRYJVjW7/8x+Vt6VCyThK0axJQ40Ze3VNhwEAAFBrHNCoXmF5M/9Vdn9x7asizjvvvCPq169ftGPHjpRBgwZteumll3KTcdyWLVvuOuecc9Z27979yPT09MLevXtvqY7jWHTM474oKyvL586dWyPHnjBhguKcQnN/NMGu0Lhx42o6DABAkvDZWXV8dtZtZva+u2dFyz788MPPevfuva6mYkLJPvzww5a9e/fukFjOOVgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJhwHSwAAACgDvn3S68eui4vv35c+2vZrOmOnwwf/FVZbVJTU/t26dKlwN2Vmprqd9xxxxdDhgzZIkkvv/xy07Fjxx6Wn5+fIkmXXHLJ12PHjl23bt261M6dO/fcsGHD/JSUFL366qtNhgwZkpGbm7ugU6dOO9evX596xBFH9NywYcP81NTUcuMcMmRIpy+//LLB1q1bUzZu3JjWtm3bHZJ01113fV4cS1mWLl1af8aMGU0vuuiiDRV6YPYSCRYAAABQh6zLy6+/qmnXHbHtMO/jcpO1Bg0aFOXk5CyWpKeeeurA6667rt2QIUOWfvHFF2kjRozo+OSTT34ycODAratWrUobPHhwl3bt2u0888wz89LT03fOmzevYd++fbe9+eabTbt37751xowZTTt16rRx5syZTXr16rWlIsmVJE2fPv0TSXr++ecPmDRpUqsZM2ZU6gLFy5Yta/DEE0+0qO4EiyGCAAAAACosLy8vtVmzZoWSNGnSpEPOOOOM9QMHDtwqSW3atCm8+eabV9x6662tJSkrKyt/1qxZTSXp3XffbXrJJZd8PXv27KaS9NZbbzU95phj8qsSy1dffZU2dOjQTj169Ojeo0eP7q+88koTSXrhhReaZmRkZGZkZGR27949c+PGjSnXX39927lz5zbNyMjInDBhwiFVOW5Z6MECAAAAUKbt27enZGRkZG7fvt3WrVtX78UXX/xYkpYsWdLovPPOWx9tO3DgwK25ubmNJOnYY4/Nf+ONNw6QtO6LL75oMHLkyI1TpkxJl6T33nuvydVXX726KnH95je/OeyKK674eujQofnLli2rP3To0C7Lly9fNGnSpNZ33nnn5yeddNKWvLy8lMaNGxfddNNNK/em56uySLAAAAAAlCk6RPDVV19tMnLkyI4ff/zxovK2y87Ozr/tttta5+Tk1G/Xrt32xo0bu7tbXl5eyqJFi5pkZ2eXe+5UWd5+++0Dly1b1qj4fn5+fmpeXl7KMccckz927NjDfvGLX2w466yzNnbq1KmoKsepDIYIAgAAAKiwwYMHb9m4cWPaqlWr0jIyMgrmzp3bOFr/9ttvN+7cuXOBJPXs2XP75s2b06ZOnXpQ//798yWpV69eW+6+++6Wbdu23d6sWbM9Ep/CwkIVD+0bM2bMoeXF4u764IMPluTk5CzOyclZvGbNmgXNmjUruvnmm1c/+OCDnxcUFKQMGjQoY968eQ3jfAzKQoIFAAAAoMLmzZvXsKioSK1atSq88sor1z7xxBMHz549u5EkrV69OvW6665rd+WVV3479K9Pnz75999//yEDBw7cIkkDBgzYct999x1y9NFHf+f8q7S0NBUnS7fffnuZMxtK0sCBAzf94Q9/+PZ8quI4Fi1a1KBfv34FN9100+pevXptWbhwYcNmzZrtys/Pr9iMGlXAEEEAAACgDmnZrOmOisz8V6n9laP4HCwp6DWaPHnyZ2lpaTr88MN3Tpky5dNRo0Z12LJlS4q728UXX/z12WefnVe87YABA/JnzZrVrDjBys7Ozr/ooosaHHvssVUaHihJDzzwwJcXXnhh+65du2bu2rXL+vfvv/nYY4/94k9/+tMhs2fPPtDMvFu3bgWnn356XkpKilJTU71bt26ZZ5999rpx48atqerxS0KCBQAAANQh5V2zqjrs2rXr/dLqhg8fnj98+PAlpdXfeOONX994441fF9/v1q3bDncvdX/lOfnkkzeffPLJm6Vg1sIXXnhheWKbRx555MuStn333Xc/3tvjVhRDBAEAAAAgJiRYAAAAABATEiwAAAAAiAnnYAHY79z+5z8qb8u2mg6jTmvWpKHGjL26psMAAKDWIcECsN/J27JN4/y2mg6jTpuw5YqaDgEAgFqJIYIAAAAAEBN6sAAAAIA65I2Xnjl0+6a1sV0Hq8GB6Tt+MPynpU79vnr16tTs7OxukrRu3bp6KSkp3qJFi0JJWrp0aaNu3boVFLd99tlnc7t167bHdbVOO+20DieffHLeyJEjN/br16/bmjVr6tWvX79o586dNmjQoM233XbbypYtW+6SpNTU1L5dunQpc38lueOOOw6ePHlyK0n65JNPGnbs2HFbSkqKTjjhhLx77713ZUUeh4kTJx5y+eWXrzvggAOKKtK+NElNsMxsiqSTJa1x9x4l1F8l6ZxIbN0lpbv7BjP7TNJmSbskFbp7VnKiBgAAAGqP7ZvW1h/S7NNyk46Kmp6nMpO11q1b78rJyVksSVdcccWhTZs23TVx4sSvJalx48ZHFddV1KOPPrr8Bz/4wdZt27bZZZdd1nb48OGd58yZs1SSGjRoUFTZ/UnS6NGj148ePXq9JLVt27bnrFmzPm7Tpk1hZfZx//33t/r1r3+9oaoJVrKHCD4saVhple5+q7v3cfc+kq6VNMvdN0SaHB/Wk1wBAAAAdVjDhg198uTJK7766qv677zzTqPqOMYNN9zQqkePHt27du2aefnllx8qSZs2bUrJzs7u3K1bt8wuXboc+de//rX573//+0PWrFlT77jjjuvav3//rlU5ZlJ7sNz9DTPrUMHmZ0n6VzWGAwAAAKAKtm/fnpKRkZEpSYcddtj26dOnf1KZ7dPS0tS9e/etCxcubDhgwICCqu4v6umnnz4wNze34YIFC5a4uwYPHtz5pZdeavr111+ntW7deufMmTNzJWn9+vWpBx988K7Jkye32puer+/8TVXZuLqYWWMFPV2XRopd0itm5pLud/cHyth+lKRRktS+ffvqDBUAAADYb+3tkL4od491f8X+85//HPjGG28cmJmZmSlJW7duTcnJyWl44oknbr7++usPu/jii9ueeuqpecOGDcuP43jFamWCJenHkt5OGB440N1XmtkhkqabWY67v1HSxmHy9YAkZWVleUltAAAAAMTv9NNP77Bw4cLGrVq12jFr1qzcstoWFhZq6dKljXv16lXqJBtRl112Wdvp06c3k6TyEjF315gxY1ZdddVV6xLrPvjgg8VPPfVUsxtuuKHtq6++uunPf/7zqoocvyJqa4J1phKGB7r7yvB2jZk9I6mfpBITLAAAAAA1Y+rUqZ9VpN327dtt9OjRbdu0abOjf//+BeVvId11110rJVVoVsDhw4dvGj9+/KGjRo3a0KxZs6JPP/20Xv369X3nzp12yCGHFP72t7/d0Lx5811/+9vfWkpSkyZNduXl5aW0adOmIrsvVa1LsMysmaTjJJ0bKWsiKcXdN4frJ0maWEMhAgAAADWmwYHpO8qb+a+y+4trXxVx3nnnHVG/fv2iHTt2pAwaNGjTSy+9VGYv19762c9+tmnRokUNjz766AxJaty4cdE//vGPT3Nychpce+217VJSUpSWlub33nvv55J0/vnnrxs2bFjXVq1a7Xjvvfc+3tvjJnua9n9JypbU0sxWSBonqZ4kuft9YbOfSnrF3bdENm0l6Rkzk4KY/+nu/0lW3AAAAEBtUdY1q6rbbbfdtsext27dOq+8bZ566qnPitf/+9//Li2rbUX2V56VK1d+VLx+ww03rLnhhhvWROuPPPLI7aeddtp3hhdef/31a66//vo1ieWVlexZBM+qQJuHFUznHi1bLql39UQFAAAAAPFI9nWwAAAAAGCfRYIFAAAA1G5FRUVFVtNBYLfw+SgqqY4ECwAAAKjdFq5du7YZSVbtUFRUZGvXrm0maWFJ9bVuFkEAAAAAuxUWFl64evXqB1evXt1DdJDUBkWSFhYWFl5YUiUJFgAAAFCL9e3bd42kU2o6DlQMGTAAAAAAxIQECwAAAABiQoIFAAAAADEhwQIAAACAmJBgAQAAAEBMSLAAAAAAICYkWAAAAAAQExIsAAAAAIgJCRYAAAAAxIQECwAAAABiQoIFAAAAADEhwQIAAACAmJBgAQAAAEBMSLAAAAAAICYkWAAAAAAQExIsAAAAAIgJCRYAAAAAxIQECwAAAABiQoIFAAAAADEhwQIAAACAmJBgAQAAAEBMSLAAAAAAICYkWAAAAAAQExIsAAAAAIgJCRYAAAAAxIQECwAAAABiQoIFAAAAADEhwQIAAACAmCQ1wTKzKWa2xswWllKfbWZ5ZjY/XP43UjfMzJaaWa6ZXZO8qAEAAACgYpLdg/WwpGHltHnT3fuEy0RJMrNUSfdIGi4pU9JZZpZZrZECAAAAQCUlNcFy9zckbdiLTftJynX35e6+Q9Ljkk6NNTgAAAAAqKLaeA7WADP70MxeMrMjw7K2kr6MtFkRlpXIzEaZ2Vwzm7t27drqjBUAAAAAvlXbEqwPJB3u7r0l3SXp33uzE3d/wN2z3D0rPT09zvgAAAAAoFS1KsFy903unh+uvyipnpm1lLRS0mGRpu3CMgAAAACoNWpVgmVmrc3MwvV+CuJbL2mOpC5m1tHM6ks6U9K0mosUAAAAAL4rLZkHM7N/ScqW1NLMVkgaJ6meJLn7fZJOl3SxmRVKKpB0pru7pEIzu1TSy5JSJU1x90XJjB0AAAAAypPUBMvdzyqn/m5Jd5dS96KkF6sjLgAAAACIQ60aIggAAAAAdVlSe7CAymroBZr5zCM1HUad1rBZuo454Yc1HQYAAMB+gQQLtVoD7VD2QV/VdBh12sxvajoCAACA/QdDBAEAAAAgJvRgAQAqjeG7VcfwXQDYN5FgAQAqjeG7VcfwXQDYNzFEEAAAAABiQoIFAAAAADFhiCAAAMA+hHMkq45zJFEVJFgAAAD7EM6RrDrOkURVMEQQAAAAAGJCggUAAAAAMSHBAgAAAICYkGABAAAAQExIsAAAAAAgJiRYAAAAABATEiwAAAAAiAkJFgAAAADEhAQLAAAAAGJCggUAAAAAMSHBAgAAAICYkGABAAAAQExIsAAAAAAgJiRYAAAAABATEiwAAAAAiAkJFgAAAADEhAQLAAAAAGJCggUAAAAAMSHBAgAAAICYkGABAAAAQExIsAAAAAAgJiRYAAAAABATEiwAAAAAiElSEywzm2Jma8xsYSn155jZAjP7yMxmm1nvSN1nYfl8M5ubvKgBAAAAoGKS3YP1sKRhZdR/Kuk4d+8p6UZJDyTUH+/ufdw9q5riAwAAAIC9lpbMg7n7G2bWoYz62ZG770pqV+1BAQAAAEBMavM5WBdIeily3yW9Ymbvm9moGooJAAAAAEqV1B6sijKz4xUkWAMjxQPdfaWZHSJpupnluPsbpWw/StIoSWrfvn21xwsAAAAAUi3swTKzXpIelHSqu68vLnf3leHtGknPSOpX2j7c/QF3z3L3rPT09OoOGQAAAAAk1bIEy8zaS3pa0i/d/eNIeRMzO6B4XdJJkkqciRAAAAAAakpShwia2b8kZUtqaWYrJI2TVE+S3P0+Sf8r6WBJ95qZJBWGMwa2kvRMWJYm6Z/u/p9kxg4AAAAA5Un2LIJnlVN/oaQLSyhfLqn3d7cAAAAAgNqjVg0RBAAAAIC6jAQLAAAAAGJCggUAAAAAMSHBAgAAAICYkGABAAAAQEwqnGCZWXcz+5mZ9Q3vf8/MXjazD8zsJjMjWQMAAACwX6vMNO3jJZ0u6XdmNl/SNEltJJmCKdS3SLo55vgAAAAAoM6oTK9T3/B2uqQsSYdKWi1pjoIkq8xrXAEAAADAvq4yCVbr8PZz7b7o782STg7X28cVFAAAAADURZVJsHaFt80UJFguabGkzXuxLwAAAADY51TmHKzlknpJeltSWwUJ1oeS2oX1X8cbGgAAAADULZXpdfqrgnOtOklqKOl5d98g6YSwfk7MsQEAAABAnVLhHix3v9fM1kv6voLzsO4Nq9ZLmiDp1fjDAwAAAIC6ozJDBOXuT0h6IqHsKUlPxRkUAAAAANRFlUqwzKyFpLGSjpfU3N0zzOzscD//cfc11RAjAAAAANQJFU6wzKyVpHckHa7gXCwPq4ZKOlfSdZL+GHeAAAAAAFBXVGaSi99L6iBpR0L5QwoSrh/HFBMAAAAA1EmVSbB+qKDXanBCefHsgZ1iiQgAAAAA6qjKJFgtw9v3EspTw9vmVQ8HAAAAAOquyiRYxRcSPiqh/Dfh7eqqhwMAAAAAdVdlEqz/KDjX6vniAjN7X9ItCoYO/ife0AAAAACgbqlMgjVeQS9VunbPINhHQdL1taSJcQYGAAAAAHVNhRMsd/9KUpaCWQNXS9qlILF6WFL/sB4AAAAA9lsVug6WmTVQcL0rSbrG3S+ovpAAAAAAoG6qUILl7tvNbKqCHq821RsSAAAAANRNlTkHa4mC862smmIBAAAAgDqtMgnWVZJ2SLrHzFqW1xgAAAAA9jcVGiIYul9SoaSfSfqpma2RtC1S7+7eKc7gAAAAAKAuqUyCdbiC6dmLhwm2Tqj372wBAAAAAPuRyiRYb4gkCgAAAABKVeEEy92zqzEOAAAAAKjzKtODJUkysyaSBkhKl7RO0mx33xJ3YAAAAABQ11QqwTKz30j6o6QDIsX5ZnaNu0+ONTIAAAAAqGMqPE27mf1Y0mRJB2r3RBemINm628xOqZYIAQAAAKCOqMx1sMaGt19JGi/pwvB2hYJEa2yJWyUwsylmtsbMFpZSb2Z2p5nlmtkCM/tepO58M1sWLudXInYAAAAAqHaVGSJ4lIJZBIe5+7fJkZk9LWmBpD4V3M/Dku6W9Ggp9cMldQmX/gp6zfqbWQtJ4yRlhXG8b2bT3H1jJf4GAAAAAKg2lenBKk7GVieUf51QXyZ3f0PShjKanCrpUQ+8K+kgM2sjaaik6e6+IUyqpksaVuHoAQAAAKCaVaYHa5mkHpL+aWY3SvpSUjtJN4T1uTHF1Dbcd7EVYVlp5d9hZqMkjZKk9u3bxxRW5aVplybYFTV2/H3BQf5NTYcAAEgiPjurjs9OoGZVJsF6VNKtkk4MlyiX9EhcQVWVuz8g6QFJysrKqrGLIxcqVQ8VZNXU4fcJYxq+VtMhAACSiM/OquOzE6hZlRki+BdJT2rPGQSLl6fD+jislHRY5H67sKy0cgAAAACoFSrcg+XuRZLOMLN7FZwP1VLBhYZfcfeZMcY0TdKlZva4gkku8tx9lZm9LOlmM2setjtJ0rUxHhcAAAAAqqRSFxqWJHefJWnW3h7QzP4lKVtSSzNboWBmwHrhvu+T9KKkHyo4p2urpJFh3Ybw3K854a4muntZk2UAAAAAQFJVOMEys6sUTKH+eHiOU3H5bySdIekld7+1vP24+1nl1LukS0qpmyJpSkVjBgAAAIBkqsw5WBdIOk7S2wnlbyjokbogppgAAAAAoE6qTIJVPN/58oTyzxLqAQAAAGC/VJkEa0d4e0xC+TEJ9QAAAACwX6pMgjVPwZTs/zCzi83sRDP7raTHFFwHa151BAgAAAAAdUVlZhG8R8E5WK0k3R0pNwUJ1l0xxgUAAAAAdU6Fe7DcfaqkCZKKtOdFhndJmuDuT1dLhAAAAABQR1TqOljuPsHMHlZwkd90SWskTXf3z6shNgCoFmnapQl2RU2HUacd5N/UdAgAANRKZSZYZmYKLgLs7r5TwcrnZvaNguGCAyVlmtlkd19W3cECQBwKlaqHCrJqOow6bUzD12o6BAAAaqXyhgjeLqlA0pPFBWZ2jaTHJZ0laaik0ZLeN7M+1RMiAAAAANQN5SVYfcPbv0uSmTWUdI32PAfLJDWV9P+qKUYAAAAAqBPKS7A6hrdzwttBkg5UMGvgO+H6b8O6gbFHBwAAAAB1SHkJVovwdlV4OyhSd7+750t6JLzfPM7AAAAAAKCuKS/B2hDedg5vh0Xqis9wTg1vv4kpJgAAAACok8qbpv0jSa0lPW9mH0vKUjA88H13Xxm2KT5Pa1UJ2wMAAADAfqO8HqyJChKqjgqufVXspsj62eHt2zHGBQAAAAB1TpkJlrvPljRc0suSlkmaKelMd39WksysqaSukt6T9FS1RgoAAAAAtVx5QwTl7tMlTS+lLl/S8XEHBQAAAAB1UXlDBAEAAAAAFUSCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMQk6QmWmQ0zs6Vmlmtm15RQ/xczmx8uH5vZN5G6XZG6aUkNHAAAAADKkZbMg5lZqqR7JA2RtELSHDOb5u6Li9u4++WR9pdJOiqyiwJ375OkcAEAAACgUpLdg9VPUq67L3f3HZIel3RqGe3PkvSvpEQGAAAAAFWU1B4sSW0lfRm5v0JS/5IamtnhkjpKej1S3NDM5koqlHSLu/+7lG1HSRolSe3bt6961ACAPWzxhvrbAq/pMOq0BgcU1HQIAIBqkOwEqzLOlDTV3XdFyg5395VmdoSk183sI3f/JHFDd39A0gOSlJWVxTcAAIjZRh2gxpmn1XQYdVrLzbk1HQIAoBoke4jgSkmHRe63C8tKcqYShge6+8rwdrmkmdrz/CwAAAAAqFHJTrDmSOpiZh3NrL6CJOo7swGaWYak5pLeiZQ1N7MG4XpLSd+XtDhxWwAAAACoKUkdIujuhWZ2qaSXJaVKmuLui8xsoqS57l6cbJ0p6XF3jw7v6y7pfjMrUpAY3hKdfRD7Js7zqDrO8wCA/QufnVXHZyeqIunnYLn7i5JeTCj734T740vYbrakntUaHGodzvOoOs7zAID9C5+dVcdnJ6oi6RcaBgAAAIB9FQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACISdITLDMbZmZLzSzXzK4poX6Ema01s/nhcmGk7nwzWxYu5yc3cgAAAAAoW1oyD2ZmqZLukTRE0gpJc8xsmrsvTmj6hLtfmrBtC0njJGVJcknvh9tuTELoAAAAAFCuZPdg9ZOU6+7L3X2HpMclnVrBbYdKmu7uG8KkarqkYdUUJwAAAABUWrITrLaSvozcXxGWJTrNzBaY2VQzO6yS28rMRpnZXDObu3bt2jjiBgAAAIBy1cZJLp6T1MHdeynopXqksjtw9wfcPcvds9LT02MPEAAAAABKkuwEa6WkwyL324Vl33L39e6+Pbz7oKS+Fd0WAAAAAGpSshOsOZK6mFlHM6sv6UxJ06INzKxN5O4pkpaE6y9LOsnMmptZc0knhWUAAAAAUCskdRZBdy80s0sVJEapkqa4+yIzmyhprrtPk/Q7MztFUqGkDZJGhNtuMLMbFSRpkjTR3TckM34AAAAAKEtSEyxJcvcXJb2YUPa/kfVrJV1byrZTJE2p1gABAAAAYC/VxkkuAAAAAKBOIsECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxSXqCZWbDzGypmeWa2TUl1F9hZovNbIGZvWZmh0fqdpnZ/HCZltzIAQAAAKBsack8mJmlSrpH0hBJKyTNMbNp7r440myepCx332pmF0v6k6QzwroCd++TzJgBAAAAoKKS3YPVT1Kuuy939x2SHpd0arSBu89w963h3XcltUtyjAAAAACwV5KdYLWV9GXk/oqwrDQXSHopcr+hmc01s3fN7CfVEB8AAAAA7LWkDhGsDDM7V1KWpOMixYe7+0ozO0LS62b2kbt/UsK2oySNkqT27dsnJV4AAAAASHYP1kpJh0XutwvL9mBmgyVdL+kUd99eXO7uK8Pb5ZJmSjqqpIO4+wPunuXuWenp6fFFDwAAAABlSHaCNUdSFzPraGb1JZ0paY/ZAM3sKEn3K0iu1kTKm5tZg3C9paTvS4pOjgEAAAAANSqpQwTdvdDMLpX0sqRUSVPcfZGZTZQ0192nSbpVUlNJT5qZJH3h7qdI6i7pfjMrUpAY3pIw+yAAAAAA1Kikn4Pl7i9KejGh7H8j64NL2W62pJ7VGx0AAAAA7L2kX2gYAAAAAPZVJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsAAAAAYkKCBQAAAAAxIcECAAAAgJiQYAEAAABATEiwAAAAACAmJFgAAAAAEJOkJ1hmNszMlppZrpldU0J9AzN7Iqx/z8w6ROquDcuXmtnQpAYOAAAAAOVIaoJlZqmS7pE0XFKmpLPMLDOh2QWSNrp7Z0l/kfTHcNtMSWdKOlLSMEn3hvsDAAAAgFoh2T1Y/STluvtyd98h6XFJpya0OVXSI+H6VEknmpmF5Y+7+3Z3/1RSbrg/AAAAAKgVzN2TdzCz0yUNc/cLw/u/lNTf3S+NtFkYtlkR3v9EUn9J4yW96+6PheV/k/SSu08t4TijJI0K73aTtLTa/ihUt5aS1tV0EAC+g/cmUHvx/qzbDnf39JoOAnsvraYDqA7u/oCkB2o6DlSdmc1196yajgPAnnhvArUX70+gZiV7iOBKSYdF7rcLy0psY2ZpkppJWl/BbQEAAACgxiQ7wZojqYuZdTSz+gomrZiW0GaapPPD9dMlve7BOMZpks4MZxnsKKmLpP8mKW4AAAAAKFdShwi6e6GZXSrpZUmpkqa4+yIzmyhprrtPk/Q3SX83s1xJGxQkYQrb/Z+kxZIKJV3i7ruSGT9qBEM9gdqJ9yZQe/H+BGpQUie5AAAAAIB9WdIvNAwAAAAA+yoSLAAAAACICQnWfsDM8mPYR5aZ3VlGfQczO7ui7UvYfqaZLTWzD81sjpn1qWLIsTGzU8zsmpqOAyiJmbmZTYrcH2tm48vZJpbXtJmNMLO1ZjbfzBaZ2VQza1zV/QJ1iZntCt8DC83sOTM7KKb9jjCzu+PYV8J+iz9v54fL6XEfIzzOHt8LgP0JCRYqxN3nuvvvymjSQdK3/0gr0L4k57h7b0n3Srq18lF+l5mlVnUf7j7N3W+JIx6gGmyX9DMza1nRDWJ+TT/h7n3c/UhJOySdEdN+gbqiIHwP9FAwOdclNR1QBZwTxtzH3adWZIPw0jmV0UGR7wXA/oQEaz9lZn3M7F0zW2Bmz5hZ87D86LBsvpndamYLw/JsM3s+XD8u8svXPDM7QNItkgaFZZcntG9qZg+Z2Ufhvk8rJ7x3JLUNt21iZlPM7L/hsU4Nyxub2f+Z2eIw/vfMLCusyzezSWb2oaQBZnZuuP18M7vfzFLD5eHwF8ePzOzycNvfhftcYGaPh2Xf/ooY/iL3elj/mpm1D8sfNrM7zWy2mS2vrl8EgRIUKpgx7PLECjP7cfjemGdmr5pZq7B8hJndbWbNzOxzM0sJy5uY2ZdmVs/MOpnZf8zsfTN708wyygoi/PLVRNLG0o5tZilmtszM0sM2KWaWa2bp4fKUBT3Yc8zs+2Gbkv7fALVV9POrn5m9E75uZ5tZt7B8hJk9Hb6/lpnZn4o3NrORZvaxmf1X0vcj5WV99kwOP8+Xh5+9U8xsiZk9XNGgzayFmf073P+7ZtYrLB9vZn83s7cVzPBcmffpHt8LqvrAAnWKu7Ps44uk/BLKFkg6LlyfKOn2cH2hpAHh+i2SFobr2ZKeD9efk/T9cL2pgun+v60vof0fi/cf3m9eQjwzJWWF62Mk3Ryu3yzp3HD9IEkfK/gSN1bS/WF5DwVfMou3d0m/CNe7h/HWC+/fK+k8SX0lTY8c/6Dw9itJDRLKRki6O/K3nx+u/0rSv8P1hyU9qeBHi0xJuTX9vLPsH4ukfEkHSvpMwYXZx0oaH9Y11+7ZYi+UNClcj76mn5V0fLh+hqQHw/XXJHUJ1/sruCZh4rFHSForab6kryW9KSm1nGOPkzQmXD9J0lPh+j8lDQzX20taEq5/5/9NTT/mLCzRReFnrILLzzwpaVh4/8Di16ukwZHX+ghJy8P3a0NJn0s6TFIbSV9ISpdUX9LbFfzseVySSTpV0iZJPcPPovcl9Skh3pmSlobv2/mSDpZ0l6RxYf0JkuaH6+PD/TQK71f4faqE7wUsLPvTktTrYKF2MLNmCpKHWWHRI5KetGDc+AHu/k5Y/k9JJ5ewi7cl3WZm/5D0tLuvMLOyDjlY4fXMJMndN5bS7h8WXIC6qaQ+YdlJkk4xs7Hh/YYK/qkPlHRHuL+FZrYgsp9dkp4K109UkEzNCWNsJGmNgg+DI8zsLkkvSHolbL8gjOPfkv5dQowDJP0sXP+7pD9F6v7t7kWSFhf3FADJ4O6bzOxRSb+TVBCpaifpCTNro+AL26clbP6EgsRqhoL36b1m1lTSsQr+LxS3a1DK4Z9w90staHiPpKsU/DhT2rGnKEjqblfwRfGhsHywpMzI8Q4M4/jO/5vyHxEgqRqZ2XwFPVdLJE0Py5tJesTMuij44a9eZJvX3D1PksxssaTDJbWUNNPd14blT0jqGrYv67PnOXd3M/tI0tfu/lG4/SIFw/TmlxDzOe4+t/iOmQ2UdJokufvrZnawmR0YVk9z9+L/KxV+n5bzvQDYpzFEEJXmwbkbFypIVt4ub+hQJZwj6QgFCd9dYZlJOs13jxVv7+5LytnPNt99EWqT9Ehk+27uPj5M8nor+CXvIkkPhu1/pOBL4vcUJGWV+RFie2SdTxYk2+2SLlDQw1vsLgW/gPeU9BsFP1AkmiZpmJm1UPBjxOsKPhu+ibxv+rh797IO7u6u4IeLH5R1bHf/UtLXZnaCpH6SXgrbp0g6JnK8tu6eX43/b4C4FLh7HwVJkmn3OVg3SprhwblZP9ae77/o58UuqUo/eBfvqyhhv0VV3G+xLZF13qdABZBg7YfCX802mtmgsOiXkma5+zeSNptZ/7D8zJK2N7NO7v6Ru/9R0hxJGZI2Syrt3Ijpipz0a+H5XqXE5pJukHRM+A/6ZUmXhb+Oy8yOCpu+LekXYVmmgiERJXlN0ulmdkjYtoWZHW7BhAAp7v6UpP8n6XsWnIdymLvPkHS1gl8fmybsb7Z2Py7nKBgSBdQ4d98g6f8UJFnFmklaGa6fX8p2+Qrex3coGM6zy903SfrUzH4uSRboXYEwBkr6pALHflDSY5KejPwY8oqky4obWDiTaCn/b4Bax923KuhFvjL8cS76HhhRgV28J+m4sPeonqSfR+qq+7PnzXC/MrNsSevC/wOJKvM+Let7AbBPI8HaPzQ2sxWR5QoFX3huDYfW9VFwHpYUfDn7azjcoYmkvBL2N8aCySEWSNqp4BfoBZJ2WTDNeuLJrL+X1Dzc5kNJx5cVbDgUYZKCoUY3KhhWsSAc7nBj2OxeSenh0IrfS1pUUqzuvlhBAvVKGO90BePc20qaGf6dj0m6VsH4+cfCYRbzJN0ZJp1Rl0kaGe7rl5JGl/W3AEk2ScEwo2LjFQzze1/SujK2e0LSueFtsXMkXRC+ZxcpOL+jJGeEJ7EvkHSUdr9Hyzr2NAU/XjwUKfudpKzwJPvFCnqWpZL/3wC1krvPU/B5eJaCYXx/MLN5qkBPkruvUvC+eUfBj4jR0RrV/dkzXlLfcP+3qJQfZFS592lZ3wuAfVrxCciApGDGv/AXbVlwnZw27l7rkggLpl+v5+7bzKyTpFcldXP3HTUcGoByWDDj51/cfVC5jQEAqGOY5AKJfmRm1yp4bXyuig1rqAmNJc0Ih1GYpN+SXAG1X/jDzcUKhyMBALCvoQcLAAAAAGLCOVgAAAAAEBMSLAAAAACICQkWAAAAAMSEBAsA9gFm9rCZeWQ5OqH+2IT6B0vbVyWPW7y/h6sScxyxAABQG5BgAcC+6VcJ9y8osRUAAIgVCRYA7JvOMrNGUnB9O0m/qOF4AADYL5BgAcC+5wtJzSSdFt4/Q1LTsPw7zOzHZjbLzDaZ2TYz+8jMxoYX9I62O9fMcs2swMxmmln30gIws7PN7B0zyw/b/9fMzigvcDM7xMz+amafh7GsN7P3zewvFf7rAQCoQSRYALDveTi8LR4mWDw88KHEhmZ2saRpkn4g6QBJDST1kHSrpH9G2p0o6VFJnSQ1lHScpNdLOriZTZT0D0nHSGoStj9a0uNmNrac2B+RdKGk9mEsLSR9T9Kvy9kOAIBagQQLAPY9j0vaIinbzE6WNEDSZklPRhuZ2QGS/hjeXSmpt6RW2p04/cLMssP1CZJM0i5JJ0tqLumVxAObWUdJ14V371GQIDWX9K+wbKKZNS8j9oHh7V8kNZKUriD5owcLAFAnkGABwL6nOJkyBb1O0u6kK+pYBb1WkvRXd1/g7mskTYy0OSkcKtgvvD/L3V9w928kjS/h2EMkFQ8tvETSBkkbJZ0VljVS0LNVms/D2x9KulbSCZJWuvsNZWwDAECtQYIFAPumv4W3zRPuR7WMrH8ZWV8RWU8P29UL76+M1H1Vwj7TKxBbizLqfiPpU0ndJP2vpCckfWJmz5tZvTK2AwCgViDBAoB9kLu/Jenj8O4id3+vhGbrIuvtSllfFy47w/ttI3WHlrPPn7i7RRdJKe7+jzLiftvdj5DUXdLPJN0RVv1IzIQIAKgDSLAAYN91o6RnJd1USv07kvLD9V+bWU8zS5f0/yJtXnH3XZKKE7TjzOyHZnaQSh4iOF1SUbj+ezPrZWb1zayDmV0S1pfKzG4ys6GSNkl6XtLTkeqK9I4BAFCj0mo6AABA9XD3xyQ9Vkb9JjO7VtJdCnqtFiQ0meruM8L18QqSo1RJL4Rl60vY53Iz+6OC86d6SPowocnnidskOEe7J8mI2qlSZi0EAKA2oQcLAPZj7n63pJ9KelNBb9Z2SYslXa3dE1PI3V+TdJ6C86O2S3pL0oml7PM6SedKmh3us0BSroJk77flhHSXpFmSvlaQVK2V9JqkH7l7YgIIAECtY+5e0zEAAAAAwD6BHiwAAAAAiAkJFgAAAADEhAQLAAAAAGJCggUAAAAAMSHBAgAAAICYkGABAAAAQExIsAAAAAAgJiRYAAAAABCT/w8LDEYygCgA/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for the bar chart\n",
    "models = ['Logistic Regression', 'Naive Bayes', 'Random Forest']\n",
    "bow_train_scores = [lr_bow_train_score, nb_bow_train_score, rf_bow_train_score]\n",
    "bow_test_scores = [lr_bow_test_score, nb_bow_test_score, rf_bow_test_score]\n",
    "tfidf_train_scores = [lr_tfidf_train_score, nb_tfidf_train_score, rf_tfidf_train_score]\n",
    "tfidf_test_scores = [lr_tfidf_test_score, nb_tfidf_test_score, rf_tfidf_test_score]\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(models))\n",
    "\n",
    "# Create the bar chart\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Training Scores\n",
    "ax.bar(index - bar_width/2, bow_train_scores, color='#1f77b4', width=bar_width, edgecolor='grey', label='BOW - Train')\n",
    "ax.bar(index - bar_width/2, tfidf_train_scores, bottom=bow_train_scores, color='#ff7f0e', width=bar_width, edgecolor='grey', label='TF-IDF - Train')\n",
    "\n",
    "# Testing Scores\n",
    "ax.bar(index + bar_width/2, bow_test_scores, color='#1f77b4', width=bar_width, edgecolor='grey', label='BOW - Test', alpha=0.5)\n",
    "ax.bar(index + bar_width/2, tfidf_test_scores, bottom=bow_test_scores, color='#ff7f0e', width=bar_width, edgecolor='grey', label='TF-IDF - Test', alpha=0.5)\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_xlabel('Models', fontweight='bold', fontsize=15)\n",
    "ax.set_ylabel('Scores', fontweight='bold', fontsize=15)\n",
    "ax.set_title('Model Performance Comparison', fontweight='bold', fontsize=18)\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(models)\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Bp6Nf4i1itS",
   "metadata": {
    "id": "5Bp6Nf4i1itS"
   },
   "source": [
    "Best Test model is Linear Regression with TF-IDF, that porve it's important to search because any models can be the best, that depend with th e context, a simple linear regression is here the most powerful with a difficult problematic than recognize stress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zVkq_2CK190O",
   "metadata": {
    "id": "zVkq_2CK190O"
   },
   "source": [
    "## Now we can visualize the first prediction with a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "zPyR8jaTNwgp",
   "metadata": {
    "id": "zPyR8jaTNwgp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Lyfmyi5bN9i9",
   "metadata": {
    "id": "Lyfmyi5bN9i9"
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with TF-IDF\n",
    "model_lr_tfidf = LogisticRegression()\n",
    "model_lr_tfidf.fit(X_train_tfidf, y_train_tfidf)\n",
    "# Evaluate the models on the test set\n",
    "# Logistic Regression with TF-IDF\n",
    "lr_tfidf_train_score = model_lr_tfidf.score(X_train_tfidf, y_train_tfidf)\n",
    "lr_tfidf_test_score = model_lr_tfidf.score(X_test_tfidf, y_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cwCN7UpuRtZC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwCN7UpuRtZC",
    "outputId": "3007b957-e0da-4911-b9a6-f2bb45088360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[243  95]\n",
      " [ 97 275]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming y_test_tfidf contains the true labels\n",
    "y_pred = model_lr_tfidf.predict(X_test_tfidf)\n",
    "cm = confusion_matrix(y_test_tfidf, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EslF67xr2G2s",
   "metadata": {
    "id": "EslF67xr2G2s"
   },
   "source": [
    "This is not perfect because stress is difficult to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hde6HE6uyGw1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Hde6HE6uyGw1",
    "outputId": "d9e25e93-bf63-4f60-c9be-94fa5cf48c44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', linewidths=.5, cbar=False)\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Logistic Regression with TF-IDF\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5qTmlGUCyvGI",
   "metadata": {
    "id": "5qTmlGUCyvGI"
   },
   "source": [
    "Now we can see our model can be effective, stress is a sentiment very difficult to sent for machine. Predictions are now possible with our best model, we can be more effective with deep learning, we can expect best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5nSRS5ZP0KmO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nSRS5ZP0KmO",
    "outputId": "af8296f3-42e3-469b-ca5f-df5583d9c4b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.72      0.72       338\n",
      "           1       0.74      0.74      0.74       372\n",
      "\n",
      "    accuracy                           0.73       710\n",
      "   macro avg       0.73      0.73      0.73       710\n",
      "weighted avg       0.73      0.73      0.73       710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the classification report\n",
    "print(classification_report(y_test_tfidf, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q5tKtA7-0TMh",
   "metadata": {
    "id": "Q5tKtA7-0TMh"
   },
   "source": [
    "Classificatication report help to provides you with a detailed breakdown of how well your model is doing in terms of precision, recall, and F1-score for each class in your dataset.\n",
    "\n",
    "  **Precision:** This is like the accuracy of your model when it claims to have found something. If it predicts a positive (e.g., spam email), precision tells you how many times it was actually correct.\n",
    "\n",
    " **Recall (Sensitivity):** This is about not missing out on positives. It tells you how many of the actual positives your model managed to capture.\n",
    "\n",
    "  **F1-Score:** This is a balance between precision and recall. Sometimes, you might have a really high precision but low recall or vice versa. F1-score gives you a single number that balances these two aspects.\n",
    "\n",
    "  **Support:** This is the number of actual occurrences of each class in your dataset. It gives you an idea of how common each class is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vDTZcKJbzd69",
   "metadata": {
    "id": "vDTZcKJbzd69"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7FiXvccp29Ih",
   "metadata": {
    "id": "7FiXvccp29Ih"
   },
   "source": [
    "We train a logistic regression model on TF-IDF data to predict stress. The stress_predictor function processes text, transforms it into TF-IDF features, and predicts stress.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2QPfxeOziN9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f2QPfxeOziN9",
    "outputId": "51127b22-2cda-4420-ef66-c447ff9212db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9059196617336153\n"
     ]
    }
   ],
   "source": [
    "# Train the logistic regression model on the TF-IDF representation\n",
    "logistic_regression_model = LogisticRegression().fit(tf_df, df1['label'])\n",
    "\n",
    "# Check the overall accuracy of the model on the training data\n",
    "accuracy = logistic_regression_model.score(tf_df, df1['label'])\n",
    "print(f\"Model Accuracy: {accuracy}\")\n",
    "\n",
    "# Define a function for making predictions\n",
    "def stress_predictor(text):\n",
    "    processed = textProcess(text)\n",
    "# Transform the processed text using the TF-IDF vectorizer\n",
    "    embedded_words = tf.transform([text])\n",
    "    res = model_lr_tfidf.predict(embedded_words)\n",
    "# Interpret the prediction result and provide a human-readable response\n",
    "    if res[0] == 1:\n",
    "        res = \"stress detected\"\n",
    "    else:\n",
    "        res = \"no stress\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hP3kUYyi3E9R",
   "metadata": {
    "id": "hP3kUYyi3E9R"
   },
   "source": [
    "The result is returned as avery good score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XN4NOVM74L20",
   "metadata": {
    "id": "XN4NOVM74L20"
   },
   "source": [
    "## Now go test with some text, i test with job situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "S9jzbIEqziQ6",
   "metadata": {
    "id": "S9jzbIEqziQ6"
   },
   "outputs": [],
   "source": [
    "text1 = \"\"\"Work today was tough. Dealing with unexpected challenges and tight deadlines.\n",
    "The pressure is on, and it's affecting my performance.\"\"\"\n",
    "text2 = \"\"\"Had a challenging day at work, but I managed to handle it well.\n",
    "Received positive feedback, boosting my confidence.\"\"\"\n",
    "text3 = \"\"\"The workload is piling up, and the constant pressure from the boss is overwhelming.\n",
    "I'm not sure how much longer I can handle this.\"\"\"\n",
    "text4 = \"\"\"Finished my tasks early today. Enjoying a sense of accomplishment and looking forward to a relaxing evening.\"\"\"\n",
    "text5 = \"\"\"\n",
    "A:Hey, Sarah. The brainstorming session today was intense, huh?\n",
    "\n",
    "B:Yeah, Mark. Intense is one word for it. It feels like the pressure is on to deliver something groundbreaking.\n",
    "\n",
    "A:Exactly. The expectations are high, and we need to step up. There's a lot riding on this project.\n",
    "\n",
    "A:I can't shake off this feeling of unease. What if we miss something important? The stakes seem so high.\n",
    "\n",
    "B:I get it, Sarah. But pressure can sometimes bring out the best in us. Let's channel that stress into motivation.\n",
    "\n",
    "A:I hope so, Mark. I just worry that we're juggling too much. The workload is starting to feel overwhelming.\n",
    "\n",
    "B:It's natural to feel that way. Let's take it one step at a time and lean on each other for support. We got this!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2s4FtJtx7Iyi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "2s4FtJtx7Iyi",
    "outputId": "70212ab4-6d23-4f77-8068-4d0d26ea9bc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work today tough dealing unexpected challenge tight deadline pressure affecting performance'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textProcess(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ibw3TITfziUU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ibw3TITfziUU",
    "outputId": "12e182ba-64ba-4124-e2c0-09af97b83545"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stress\n",
      "no stress\n",
      "stress detected\n",
      "no stress\n",
      "no stress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicol\\anaconda3\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(stress_predictor(text1))\n",
    "print(stress_predictor(text2))\n",
    "print(stress_predictor(text3))\n",
    "print(stress_predictor(text4))\n",
    "print(stress_predictor(text5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zuZ5GtA39RsH",
   "metadata": {
    "id": "zuZ5GtA39RsH"
   },
   "source": [
    "The key takeaway is the significance of aligning algorithm selection with the unique characteristics of the problem at hand.\n",
    "This exploration underscores the nuanced interplay between algorithms and performance, offering valuable insights for fellow students venturing into machine learning projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "l8L4YnMz9rCG",
   "metadata": {
    "id": "l8L4YnMz9rCG"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedNCLAz9y2J",
   "metadata": {
    "id": "aedNCLAz9y2J"
   },
   "source": [
    "In conclusion, The exploration encompassed Bag of Words (BOW) and Term Frequency-Inverse Document Frequency (TF-IDF) methods, coupled with models like Logistic Regression, Naive Bayes, and Random Forest. Notably, the Random Forest algorithm didn't necessarily yield superior results, emphasizing the significance of algorithm selection based on the unique characteristics of the problem.\n",
    "\n",
    "Looking ahead, an exciting avenue for further exploration involves delving into deep learning techniques, particularly using PyTorch. The transition to deep learning could unlock the potential for capturing intricate patterns and dependencies within textual data, enhancing the model's ability to discern nuanced emotions and stress indicators. This foray into deep learning represents a promising extension of the stress detection project, offering a more sophisticated approach for future enhancements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0c7b10",
   "metadata": {},
   "source": [
    "Nicolas WATTENHOFFER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5bf531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
